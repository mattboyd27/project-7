---
title: "A Machine Learning Approach to MLB Catcher Framing"
author: "Nathan Hemenway and Matthew Boyd"
date: "12/10/2021"
output: 
  beamer_presentation: default
---

```{r setup, include=FALSE}
library(tidyverse)
library(gbm)
library(randomForest)
knitr::opts_chunk$set(echo = FALSE)
```

## Introduction

- "Catcher framing is the art of a catcher receiving a pitch in a way that makes it more likely for an umpire to call it a strike -- whether that's turning a borderline ball into a strike, or not losing a strike to a ball due to poor framing." - MLB.com Glossary

## Motivation

- Baseball catchers can influence the call of a ball or strike on how they catch the ball
- Some catchers are better than others at this skill
- Baseball teams are aware of this and are acquiring players good at this skill to win more games
- We want to quantify the best catcher's at framing for the 2021 season
- There are several factors that influence whether a pitch will be a strike or ball
- Catchers getting more strikes translates to more outs, and fewer runs for the opposing team

## Data

- 2021 pitch data scraped from Baseball Savant through baseballr package
- ~700,000 rows (each for a single pitch)
- Wanted to look at pitches that were not swung at by the batter (called strike or ball)
- ~350,000 rows remain

## Variables

- We used:
- Pitch type and pitch release speed, position, and spin rate
- Whether or not the pitcher and batter are right or left handed
- Count, number of outs during the at-bat, and inning number
- Where the pitch landed
- Whether the game was played home or away
- How tall the batter is

## Example

- Strike Probability by Location and Count

```{r cars, echo = FALSE, message = FALSE, cache=TRUE}
load("Data/usable_data.Rda")
x=c(-0.95,0.95,0.95,-0.95,-0.95)
y=c(1.5,1.5,3.5,3.5,1.5)
sz=data.frame(x,y)
# Take some samples to explore
train = usable_data %>% slice(1000:150000) %>%
  mutate(strike = as.character(strike)) %>%
  select(-catcher_name)

# Train initial model

model = gbm(strike ~ plate_x + plate_z + count, 
                     data = train, n.trees = 200, distribution = "bernoulli")


# Create a grid of values
grid1 = data.frame()
x = seq(-1.8, 1.8, length.out = 125)
y = seq(1.2, 3.8, length.out = 125)
grid = expand.grid(plate_x = x, plate_z = y)

# This creates a new grid for every count factor to visualize
grid1 = grid1 %>% bind_rows(data.frame(grid, count = "0-0"),
                            data.frame(grid, count = "0-1"),
                            data.frame(grid, count = "0-2"),
                            data.frame(grid, count = "1-0"),
                            data.frame(grid, count = "1-1"),
                            data.frame(grid, count = "1-2"),
                            data.frame(grid, count = "2-0"),
                            data.frame(grid, count = "2-1"),
                            data.frame(grid, count = "2-2"),
                            data.frame(grid, count = "3-0"),
                            data.frame(grid, count = "3-1"),
                            data.frame(grid, count = "3-2")) %>%
  mutate(count = as.factor(count))


# Predict whether a pitch will be a strike or not
grid1 = grid1 %>%
  mutate(pred = predict(model, grid1, type = "response") >= 0.5)

# Visualize strikes by the count and location
ggplot()+
  geom_point(data = grid1, aes(x = plate_x, y = plate_z, color = pred)) +
  facet_wrap(~count) +
  geom_path(data = sz, aes(x = x, y = y)) +
  scale_color_manual(values = c("TRUE" = "red", "FALSE" = "white")) +
  labs(color = "Predicted Strike") +
  theme(axis.title.x = element_blank(),
        axis.text.x = element_blank(),
        axis.title.y = element_blank(),
        axis.text.y = element_blank())
```

## Logistic Regression Model

\tiny
```{r, echo=FALSE}
data_no_catchers <- usable_data[, -18]

train <- sample(1:nrow(data_no_catchers), nrow(data_no_catchers)/2)
test <- (-train)

log_reg_fit <- glm(strike ~ ., data=data_no_catchers[train, ], family='binomial')
summary(log_reg_fit)

pred <- predict.glm(log_reg_fit, type='response', newdata = data_no_catchers[test, ])
pred[pred >= 0.5] <- 'strike'
pred[pred < 0.5] <- 'ball'
sum(pred=='strike')/length(pred)

```

```{r}
conf_mx <- table(pred=pred, true=data_no_catchers[test, ]$strike)
error <- (conf_mx[2] + conf_mx[3])/length(pred)

conf_mx
error
```


## Random Forest

- Tested several Random Forest models
  - Nodesize: 10, 30, 50, 70, 90 | # of Trees: 500
  - Compared Out-Of-Bag Error 
```{r, echo=FALSE, fig.width=7, fig.height=3}
load("Data/pitchData.Rda")
load("Model-Outputs/random-forest.Rda")

ggplot(df_rf, aes(x = nodesize, y = accuracy))+
  geom_line() +
  geom_point() +
  geom_point(data = df_rf %>% 
               filter(accuracy == max(accuracy)), aes(x = nodesize, y = accuracy), color = "red") +
  ylim(0.925, 0.935) +
  labs(x = "Nodesize",
       y = "Accuracy",
       title = "Random Forest OOB Accuracy by Nodesize") +
  theme_minimal()
```


## Boosting

- 3 Fold Cross Validation on Boosting
  - Interaction depth: 6, 11, 16 
  - Shrinkage: 0.1, 0.01, 0.001 
  - Number of Trees: 500
  - Compared CV accuracy
- 27 models took over 5 hours to run
  
```{r, echo=FALSE, fig.width=6, fig.height=2.5}
load("Model-Outputs/boosting.Rda")

ggplot(df_gbm_final, aes(x = interaction_depth, y = accuracy, color = as.character(lambda))) +
  geom_line() +
  theme_minimal()+
  geom_point() +
  geom_point(aes(x = 16, y = 0.935), color = "red") +
  labs(x = "Accuracy", y = "Interactin Depth",
       color = "Shrinkage",
       y = "Boosting Accuracy by Interaction Depth and Shrinkage")
```


## Boosting Part 2

- Only tuned shrinkage and interaction depth
- Now tune trees with interaction depth of 16 and shrinkage of 0.1

```{r}
load("Model-Outputs/boosting2.Rda")
final_df_gbm %>%
  group_by(trees) %>%
  summarize(accuracy = mean(accuracy)) %>%
  arrange(desc(accuracy)) %>%
  ggplot(aes(x = trees, y = accuracy)) +
  geom_line(color = "goldenrod") +
  theme_minimal() +
  labs(x = "Number of Trees",
       y = "Accuracy",
       title = "Boosting Accuracy by # of Trees")
```

